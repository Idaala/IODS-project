
# **Part 2 Analysis (max 15 points)**


## Introduction
### A brief description of the data 

The study's goal is to determine the association between students' learning styles and their academic achievements.
There are 60 variables and 183 observations. The majority of the questions are about learning, and the answers are given on a Likert scale of 1 to 5. There are also some background variables (age, attitude toward statistics, points) included.
Deep learning, surface learning, and strategic learning variables are generated by combining questions that can be regarded of as measuring the same dimension. The average of the combination variables is calculated. 


## Read the data and explore the structure and the dimension of the dataframe

```{r, }
students2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep = ",", header=TRUE)

str(students2014)
dim(students2014)

library("ggplot2")                     
library("GGally")

```

## More exploring

```{R}

summary(students2014)
```

in the summary, we can see that gender is a character variable. The rest of the variables are numeric. 

## graphical overview of the data. 

```{R}
plot(students2014$attitude, students2014$points)
plot(students2014$stra, students2014$points)

p1 <- ggplot(students2014, aes(x = attitude, y = points))

p2 <- p1 + geom_point()

p2

p3 <- p2 + geom_smooth(method = "lm")

p3


```

It appears that having a positive attitude leads to better performance. The correlation between all of the variables can be examined. 

```{R}
cor(students2014$attitude, students2014$points)

ggpairs(students2014, title = "correlogram with ggpairs", lower= list(combo = wrap("facethist", bins = 20)))

ggpairs(students2014, columns = 2:4, ggplot2::aes(colour=gender)) 

```

## Regression model fitting

The scatterplotmatrix shows that attitude (0.436), stra (0.146), and surf (-0,144) have the strongest correlations with points.However, the correlation is much weaker for stra and surf compared to attitude. As a result, these variables will function as explanatory variables. Exam points are the target (dependent) variable in a regression model. The age distribution reveals that the majority of students are in their twenties, as one might expect.The gender distribution is skewed, with slightly more females than males enrolling in the course. 


```{R}
reg_model <- lm(points ~ attitude + stra + surf, data = students2014)
summary(reg_model) 
```
The only variable that appears to correlate statistically significant in explaining points appears to be attitude. Let's get rid of some variables and try different versions.

```{R}
reg_model1 <- lm(points ~ attitude + stra, data = students2014)

summary(reg_model1)

#let us try another versions

reg_model2 <- lm(points ~ attitude + surf, data = students2014)

summary(reg_model2)

reg_model3 <- lm(points ~ attitude, data=students2014)

summary(reg_model3) 
```
In conclusion, a more cheerful attitude leads to better exam outcomes.It's possible that having a happy mindset earns you more points. 

## Interpretation of R-squared

The R-squared (R2) statistic measures the proportion of a dependent variable's variance explained by the independent variable or variables in a regression model.R-squared explains how much variance of one variable can be explained by the variance of another variable, whereas correlation explains the strength of the relationship between independent and dependent variables. The R2 of a model is 0.50, which means that approximately half of the observed variation can be explained by the model's inputs. Which means a higher R2 value, the better it fits the model. the R2-value becomes lower as the variables are removed. This indicates a poorer fit. 

R2-values of the different regression models

reg_model= 0.2074

reg_model1= 0.2048

reg_model2= 0.1953

reg_model3=  0.1906

reg_model have the highest r2-value. Now we can check how good the model actually is. 

```{r}
errors <- plot(reg_model, which= c(1,2,5), par(mfrow= c(2,2)))
```

## Conclusion

More or less points are closer to the straight line. Almost all points fall approximately along this straight line, so we can assume normality. We can observe in plot 1 that values are reasonably widely distributed throughout the area, indicating that errors do not follow any pattern, as one would anticipate from a reasonable model. Additionally, there are no extreme outliers.




