
# **Part 2 Analysis (max 15 points)**

### 1. Read the data

```{R}
students2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep = ",", header=TRUE)

str(students2014)
dim(students2014)

library("ggplot2")                     
library("GGally")

```

### 2. explore the data

```{R}

summary(students2014)


```

###in the summary, we can see that gender is a character variable. The rest of the variables are numeric. 

### graphical overview of the data. We can plots of some variables

```{R}
plot(students2014$attitude, students2014$points)

plot(students2014$stra, students2014$points)
```

### It appears that having a positive attitude leads to better performance. The correlation between all of the variables can be examined. 

```{R}
cor(students2014$attitude, students2014$points)

ggpairs(students2014, title = "correlogram with ggpairs", lower= list(combo = wrap("facethist", bins = 20)))

ggpairs(students2014, columns = 2:4, ggplot2::aes(colour=gender)) 

```
### The scatterplotmatrix shows that attitude (0.436), stra (0.146), and surf (-0,144) have the strongest correlations with points. As a result, these variables will function as explanatory variables. fit a regression model where exam points is the target (dependent) variable.

```{R}
reg_model <- lm(points ~ attitude + stra + surf, data = students2014)

summary(reg_model) 
```
### The only variable that appears to correlate statistically significant in explaining points appears to be attitude. Let's get rid of some variables and try different versions.

```{R}

reg_model1 <- lm(points ~ attitude + stra, data = students2014)

summary(reg_model1)

#let us try another versions

reg_model2 <- lm(points ~ attitude + surf, data = students2014)

summary(reg_model2)

reg_model3 <- lm(points ~ attitude, data=students2014)

summary(reg_model3) 
```
### In conclusion, a more cheerful attitude leads to better exam outcomes.It's possible that having a happy mindset earns you more points. 

## Interpretation of R-squared

### The R-squared (R2) statistic measures the proportion of a dependent variable's variance explained by the independent variable or variables in a regression model.R-squared explains how much variance of one variable can be explained by the variance of another variable, whereas correlation explains the strength of the relationship between independent and dependent variables. The R2 of a model is 0.50, which means that approximately half of the observed variation can be explained by the model's inputs. Which means a higher R2 value, the better it fits the model. the R2-value becomes lower as the variables are removed. This indicates a poorer fit. 

### R2-values of the different regression models

### reg_model= 0.2074
### reg_model1= 0.2048
### reg_model2= 0.1953
### reg_model3=  0.1906

### reg_model have the highest r2-value. Now we can check how good the model actually is. 

```{r}

errors <- plot(reg_model, which= c(1,2,5), par(mfrow= c(2,2)))


```

## Conclusion

### More or less points are closer to the straight line. Almost all points fall approximately along this straight line, so we can assume normality. We can observe in plot 1 that values are reasonably widely distributed throughout the area, indicating that errors do not follow any pattern, as one would anticipate from a reasonable model. 




